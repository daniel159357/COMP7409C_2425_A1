import numpy as np 

class Perceptron():
  def init(self, eta=0.01, nepoch=10, random_state=1): 
    ''' comments
    Meaning of the parameters:
    eta: learning rate (a small float number between 0.0 and 1.0) nepoch: No of passes over the whole training dataset random_state: for fixing the initial state of the generator for
    random numbers so that yours will be the same as those generated by our TAs' program.
    '''
    #   insert statements below for setting self.eta, self.nepoch and self.random_state by the arguments of the function.
  
  def fit(self, X, y):
    ''' comments
    meaning of the parameters:
    X: traning data, which is a 2D array with shape (n_examples, n_features) where n_examples is the number of examples and n_features is the number of features
    y: labels, which is a 1D array with shape (n_examples)
    '''
    # the following statements are for initializing the weights by some small random numbers.rgen is the random number generator with its random_state
    # fixed at the one you given when you create the object by Preceptron()
    rgen = np.random.RandomState(self.random_state)
    # the following statement asks the generator to generate, for each weight, a random number from the normal distribution with mean = 0 and standard deviation 0.01.
    self.w = rgen.normal(loc=0.0, scale=0.01,
    size = 1 + X.shape[1])
    # the list self.errors is for recording the total number of errors made in each epoch.
    self.errors = []
    # the following for loop processes the whole data set for weight updates for self.nepoch times
    for _ in range(self.nepoch):
      errors = 0
    # insert necessary statements below to read in each (example, label) pair and update the weights using the Perceptron learning rules given in the lecture.
    # ...
    # end of loop
    # insert necessary statements below to append the number of errors found in this round to self.errors here
    # ...
    return self
  
  def net_input(self, x):
    ''' comments
    As can be seen in the function fit(), the weights are stored in
    the array self.w. For the argument x, it represents
    an example with feature x_1, x_2, ..., x_n and
    the function returns the net input
    self.w_0 + self.w1*x_1 + self.w2*x_2 + ... + self.w_n *xn
    '''
    # insert statements below to complete the function definition.
  
  def predict(self, X):
    '''comments
    return the class labels for the data set X based
    on their net inputs.
    '''
    # insert statements below to complete the function definition.
